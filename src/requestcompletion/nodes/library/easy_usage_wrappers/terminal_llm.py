import warnings
from typing import Type, Dict, Any
from ..terminal_llm import TerminalLLM
from ....llm import MessageHistory, ModelBase, SystemMessage, UserMessage
from ....llm.tools import Parameter, Tool
from copy import deepcopy
from ....exceptions.node_creation.validation import (
    check_tool_params_and_details,
    check_duplicate_param_names,
    check_system_message,
    check_pretty_name,
)


def terminal_llm(  # noqa: C901
    pretty_name: str | None = None,
    system_message: SystemMessage | None = None,
    model: ModelBase | None = None,
    tool_details: str | None = None,
    tool_params: set[Parameter] | None = None,
) -> Type[TerminalLLM]:
    class TerminalLLMNode(TerminalLLM):
        def __init__(
            self,
            message_history: MessageHistory,
            llm_model: ModelBase | None = None,
        ):
            message_history_copy = deepcopy(message_history)
            if system_message is not None:
                if len([x for x in message_history_copy if x.role == "system"]) > 0:
                    warnings.warn(
                        "System message already exists in message history. We will replace it."
                    )
                    message_history_copy = [
                        x for x in message_history_copy if x.role != "system"
                    ]
                    message_history_copy.insert(0, system_message)
                else:
                    message_history_copy.insert(0, system_message)

            if llm_model is not None:
                if model is not None:
                    warnings.warn(
                        "You have provided a model as a parameter and as a class variable. We will use the parameter."
                    )
            else:
                if model is None:
                    raise RuntimeError(
                        "You MUST provide an LLM model to the TerminalLLM class"
                    )
                llm_model = model

            super().__init__(message_history=message_history_copy, model=llm_model)

        @classmethod
        def pretty_name(cls) -> str:
            if pretty_name is None:
                return "TerminalLLM"
            else:
                return pretty_name

        if tool_details:  # params might be empty

            @classmethod
            def tool_info(cls) -> Tool:
                return Tool(
                    name=cls.pretty_name().replace(" ", "_"),
                    detail=tool_details,
                    parameters=tool_params,
                )

            @classmethod
            def prepare_tool(cls, tool_parameters: Dict[str, Any]) -> TerminalLLM:
                message_hist = MessageHistory(
                    [
                        UserMessage(f"{param.name}: '{tool_parameters[param.name]}'")
                        for param in (tool_params if tool_params else [])
                    ]
                )
                return cls(message_hist)

    check_tool_params_and_details(tool_params, tool_details)
    check_duplicate_param_names(tool_params or [])
    check_system_message(system_message, SystemMessage)
    check_pretty_name(pretty_name, tool_details)
    return TerminalLLMNode
